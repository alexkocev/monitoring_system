{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------\n",
    "# - IMPORTS -\n",
    "# -----------\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from anthropic import Anthropic\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# BigQuery Credentials and Table Information\n",
    "BQ_PATH_KEY = os.getenv(\"BQ_PATH_KEY\")              # \"/path/to/your/service-account-key.json\" generated from BQ. Should be in the same directory as this script\n",
    "BQ_PROJECT_ID = os.getenv(\"BQ_PROJECT_ID\")          # \"project-id\"\n",
    "BQ_DATASET_ID = os.getenv(\"BQ_DATASET_ID\")        # \"dataset-id\"\n",
    "BQ_TABLE_ID = os.getenv(\"BQ_TABLE_ID\")        # \"table-id\"\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")   \n",
    "\n",
    "SLACK_TOKEN = os.getenv(\"SLACK_TOKEN\")       \n",
    "SLACK_CHANNEL_ID = os.getenv(\"SLACK_CHANNEL_ID\")      \n",
    "\n",
    "# Set the Google Cloud credentials environment variable\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = BQ_PATH_KEY\n",
    "\n",
    "# Initialize a BigQuery client\n",
    "client = bigquery.Client(project=BQ_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# -- Fetch and analyze GA4-Magento data from BigQuery -----\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def fetch_existing_data_from_bq():\n",
    "    try:\n",
    "        # Check if the table has a schema by getting table metadata\n",
    "        table_ref = f\"{BQ_PROJECT_ID}.{BQ_DATASET_ID}.{BQ_TABLE_ID}\"\n",
    "        table = client.get_table(table_ref)\n",
    "\n",
    "        # If table has no schema, return an empty DataFrame\n",
    "        if not table.schema:\n",
    "            print(f\"Table {BQ_TABLE_ID} exists but has no schema. Returning empty DataFrame.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # If table exists and has a schema, query the data\n",
    "        query = f\"\"\"\n",
    "            SELECT\n",
    "            order_date,\n",
    "            COUNT(DISTINCT magento_transaction_id) AS magento_transactions,\n",
    "            COUNT(DISTINCT ga4_transaction_id) AS ga4_transactions,\n",
    "            SAFE_DIVIDE(\n",
    "                COUNT(DISTINCT ga4_transaction_id), \n",
    "                COUNT(DISTINCT magento_transaction_id)\n",
    "            ) * 100 AS transaction_coverage_rate,\n",
    "            SUM(magento_revenue) AS magento_revenue,\n",
    "            SUM(ga4_revenue) AS ga4_revenue,\n",
    "            SAFE_DIVIDE(\n",
    "                SUM(ga4_revenue), \n",
    "                SUM(magento_revenue)\n",
    "            ) * 100 AS revenue_coverage_rate\n",
    "            FROM {BQ_PROJECT_ID}.{BQ_DATASET_ID}.{BQ_TABLE_ID}\n",
    "            GROUP BY order_date\n",
    "            ORDER BY order_date DESC\n",
    "\n",
    "            \"\"\"\n",
    "        query_job = client.query(query)\n",
    "        df_existing = query_job.to_dataframe()\n",
    "        return df_existing\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data from table {BQ_TABLE_ID}: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "df = fetch_existing_data_from_bq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# --    Remove most recent rows as GA4 is not accurate   -----\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def remove_last_24hours_rows(df):\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "    # Get the current time and subtract 24 hours\n",
    "    current_time = datetime.now()\n",
    "    time_24_hours_ago = current_time - timedelta(hours=24)\n",
    "\n",
    "    # Get the day before that time (i.e., yesterday)\n",
    "    day_before_24_hours = time_24_hours_ago.date()\n",
    "\n",
    "    # Filter the DataFrame to keep only rows up to the day before the given day\n",
    "    df_filtered = df[df['order_date'].dt.date < day_before_24_hours]\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "df = remove_last_24hours_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# --       Format df into markdown for Claude analysis   -----\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def generate_table_for_analysis(df):\n",
    "    # Split data into transactions and revenue sections\n",
    "    tx_table = df[['order_date', 'magento_transactions', 'ga4_transactions', 'transaction_coverage_rate']]\n",
    "    rev_table = df[['order_date', 'magento_revenue', 'ga4_revenue', 'revenue_coverage_rate']]\n",
    "    \n",
    "    # Convert both tables to markdown\n",
    "    tx_table_md = tx_table.to_markdown(index=False)\n",
    "    rev_table_md = rev_table.to_markdown(index=False)\n",
    "    \n",
    "    return tx_table_md, rev_table_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# --   Generate the analysis prompt for Claude based on the tables   -----\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def analyze_with_claude(df):\n",
    "    # Prepare the tables in markdown format\n",
    "    tx_table_md, rev_table_md = generate_table_for_analysis(df)\n",
    "    \n",
    "    # Build the prompt\n",
    "    prompt = f\"\"\"\n",
    "    I need you to analyze our GA4-Magento coverage rates and provide a standardized daily report. The data shows a comparison between Magento (our source of truth) and GA4 tracking.\n",
    "\n",
    "    ## Context\n",
    "    - The data covers {df.order_date.min().strftime('%b %d')} to {df.order_date.max().strftime('%b %d, %Y')}\n",
    "    - We consider coverage rates below 80% as concerning and below 50% as critical issues\n",
    "    - Normal coverage rate for our business is typically between 80-95%\n",
    "    - The most recent data is from **{df.order_date.max().strftime('%b %d, %Y')}** (note: we wait 24 hours to ensure GA4 data is complete)\n",
    "\n",
    "    ## Transactions Coverage Data\n",
    "    This table shows the number of transactions recorded by Magento vs GA4, as well as the transaction coverage rate.\n",
    "    {tx_table_md}\n",
    "\n",
    "    ## Revenue Coverage Data\n",
    "    This table shows the revenue generated according to Magento vs GA4, as well as the revenue coverage rate.\n",
    "    {rev_table_md}\n",
    "\n",
    "    ## Output Format Requirements\n",
    "    Your analysis must strictly follow this format:\n",
    "\n",
    "    ```\n",
    "    [EMOJI] [only few words for the hilight] - [latest_date]\n",
    "    \n",
    "    - *Transactions*: 716 (Magento) vs 589 (GA4)\n",
    "    - *Transaction Coverage*: 82.3% (↑ 3.5%)\n",
    "    - *Revenue*: $40.8K (Magento) vs $32.7K (GA4)\n",
    "    - *Revenue Coverage*: 80.1% (↑ 1.8%)\n",
    "\n",
    "    🔍 *Overall Trend*: Transaction coverage has improved above 80% after a week of below-threshold performance, but revenue coverage remains at the minimum acceptable level. Continued monitoring needed.\n",
    "\n",
    "    📊 *Dashboard* for further analysis: https://lookerstudio.google.com/reporting/112b5f97-bb39-4f07-802f-6a5481dbc76e\n",
    "    ```\n",
    "\n",
    "    ## Status Indicators\n",
    "    Select the appropriate emoji indicator based on these criteria:\n",
    "    - **Critical (🚨)**: If there's a significant drop compared to previous data or if coverage is below 50%\n",
    "    - **Warning (⚠️)**: If coverage is below 80% or if there's a slight drop over several days\n",
    "    - **Good (✅)**: If coverage is stable and above 70%\n",
    "\n",
    "    ## Direction Indicators\n",
    "    For changes:\n",
    "    - Use (↑) for increases in coverage\n",
    "    - Use (↓) for decreases in coverage\n",
    "    - Use (→) for no change in coverage (less than 0.1% change)\n",
    "\n",
    "    ## Important Notes\n",
    "    1. Use exactly the format shown above, including bullet points, bolding, and emoji placement\n",
    "    2. Keep the \"Overall Trend\" to 1-2 concise sentences focusing on the most important insight\n",
    "    3. Always include the dashboard link in the exact format shown\n",
    "    4. Round percentages to 1 decimal place\n",
    "    5. Format numbers with thousands separators (e.g., 1,503)\n",
    "    6. Format revenue in thousands (K) with 1 decimal place\n",
    "\n",
    "    Your entire response should be exactly in this format without any additional text or explanations.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize Anthropic client (using their direct API instead of langchain)\n",
    "    client = Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "    \n",
    "    # Send the prompt to Claude\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract analysis text\n",
    "    analysis = response.content[0].text\n",
    "    print(\"Completed Claude analysis\")\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Example usage:\n",
    "# Get Claude's analysis of the data tables\n",
    "analysis = analyze_with_claude(df)\n",
    "\n",
    "# Output Claude's response\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# --   Send to Slack   -----\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def send_message_to_channel(message_text):\n",
    "    slack_client = WebClient(token=SLACK_TOKEN)\n",
    "\n",
    "    try:\n",
    "        # Post message to the channel\n",
    "        response = slack_client.chat_postMessage(\n",
    "            channel=SLACK_CHANNEL_ID,\n",
    "            text=message_text\n",
    "        )\n",
    "        print(f\"Message sent successfully: {response['ts']}\")\n",
    "        return response\n",
    "    except SlackApiError as e:\n",
    "        print(f\"Error sending message: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# send_message_to_channel(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"\"\"\n",
    "Hello team! 👋\n",
    "\n",
    "I'm your Data Detective 🤖\n",
    "\n",
    "I analyze the Magento vs GA4 tracking coverage for qwertee.com and send you automated alerts every morning at 09:00 LTV time. Using AI, I scan and evaluate the past 90 days of data to identify trends and potential issues.\n",
    "\n",
    "Note that I exclude the most recent 24-48 hours from my analysis since GA4 data isn't real-time and needs time to fully process.\n",
    "\n",
    "For deeper insights and visualizations, check out our dashboard:\n",
    "https://lookerstudio.google.com/reporting/112b5f97-bb39-4f07-802f-6a5481dbc76e\n",
    "\n",
    "Looking forward to keeping you updated on our tracking health! If coverage drops below our thresholds, I'll let you know!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_message_to_channel(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
